from typing import List, Union
from langchain_experimental.tools import PythonAstREPLTool
from langchain_teddynote import logging
from langchain_teddynote.messages import AgentStreamParser, AgentCallbacks
from dotenv import load_dotenv
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

##### í°íŠ¸ ì„¤ì • #####
import platform

# OS íŒë‹¨
current_os = platform.system()

if current_os == "Windows":
    # Windows í™˜ê²½ í°íŠ¸ ì„¤ì •
    font_path = "C:/Windows/Fonts/malgun.ttf"  # ë§‘ì€ ê³ ë”• í°íŠ¸ ê²½ë¡œ
    fontprop = fm.FontProperties(fname=font_path, size=12)
    plt.rc("font", family=fontprop.get_name())
elif current_os == "Darwin":  # macOS
    # Mac í™˜ê²½ í°íŠ¸ ì„¤ì •
    plt.rcParams["font.family"] = "AppleGothic"
else:  # Linux ë“± ê¸°íƒ€ OS
    # ê¸°ë³¸ í•œê¸€ í°íŠ¸ ì„¤ì • ì‹œë„
    try:
        plt.rcParams["font.family"] = "NanumGothic"
    except:
        print("í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

##### ë§ˆì´ë„ˆìŠ¤ í°íŠ¸ ê¹¨ì§ ë°©ì§€ #####
plt.rcParams["axes.unicode_minus"] = False  # ë§ˆì´ë„ˆìŠ¤ í°íŠ¸ ê¹¨ì§ ë°©ì§€

# API í‚¤ ë° í”„ë¡œì íŠ¸ ì„¤ì •
load_dotenv()
logging.langsmith("CSV Agent ì±—ë´‡")

# Streamlit ì•± ì„¤ì •
st.title("CSV ë°ì´í„° ë¶„ì„ ì±—ë´‡ ğŸ’¬")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state["messages"] = []  # ëŒ€í™” ë‚´ìš©ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”


# ìƒìˆ˜ ì •ì˜
class MessageRole:
    """
    ë©”ì‹œì§€ ì—­í• ì„ ì •ì˜í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    """

    USER = "user"  # ì‚¬ìš©ì ë©”ì‹œì§€ ì—­í• 
    ASSISTANT = "assistant"  # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì—­í• 


class MessageType:
    """
    ë©”ì‹œì§€ ìœ í˜•ì„ ì •ì˜í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    """

    TEXT = "text"  # í…ìŠ¤íŠ¸ ë©”ì‹œì§€
    FIGURE = "figure"  # ê·¸ë¦¼ ë©”ì‹œì§€
    CODE = "code"  # ì½”ë“œ ë©”ì‹œì§€
    DATAFRAME = "dataframe"  # ë°ì´í„°í”„ë ˆì„ ë©”ì‹œì§€


# ë©”ì‹œì§€ ê´€ë ¨ í•¨ìˆ˜
def print_messages():
    """
    ì €ì¥ëœ ë©”ì‹œì§€ë¥¼ í™”ë©´ì— ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.
    """
    for role, content_list in st.session_state["messages"]:
        with st.chat_message(role):
            for content in content_list:
                if isinstance(content, list):
                    message_type, message_content = content
                    if message_type == MessageType.TEXT:
                        st.markdown(message_content)  # í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì¶œë ¥
                    elif message_type == MessageType.FIGURE:
                        st.pyplot(message_content)  # ê·¸ë¦¼ ë©”ì‹œì§€ ì¶œë ¥
                    elif message_type == MessageType.CODE:
                        with st.status("ì½”ë“œ ì¶œë ¥", expanded=False):
                            st.code(
                                message_content, language="python"
                            )  # ì½”ë“œ ë©”ì‹œì§€ ì¶œë ¥
                    elif message_type == MessageType.DATAFRAME:
                        st.dataframe(message_content)  # ë°ì´í„°í”„ë ˆì„ ë©”ì‹œì§€ ì¶œë ¥
                else:
                    raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” ì½˜í…ì¸  ìœ í˜•: {content}")


def add_message(role: MessageRole, content: List[Union[MessageType, str]]):
    """
    ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Args:
        role (MessageRole): ë©”ì‹œì§€ ì—­í•  (ì‚¬ìš©ì ë˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸)
        content (List[Union[MessageType, str]]): ë©”ì‹œì§€ ë‚´ìš©
    """
    messages = st.session_state["messages"]
    if messages and messages[-1][0] == role:
        messages[-1][1].extend([content])  # ê°™ì€ ì—­í• ì˜ ì—°ì†ëœ ë©”ì‹œì§€ëŠ” í•˜ë‚˜ë¡œ í•©ì¹©ë‹ˆë‹¤
    else:
        messages.append([role, [content]])  # ìƒˆë¡œìš´ ì—­í• ì˜ ë©”ì‹œì§€ëŠ” ìƒˆë¡œ ì¶”ê°€í•©ë‹ˆë‹¤


# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    clear_btn = st.button("ëŒ€í™” ì´ˆê¸°í™”")  # ëŒ€í™” ë‚´ìš©ì„ ì´ˆê¸°í™”í•˜ëŠ” ë²„íŠ¼
    uploaded_file = st.file_uploader(
        "CSV íŒŒì¼ì„ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”.", type=["csv"]
    )  # CSV íŒŒì¼ ì—…ë¡œë“œ ê¸°ëŠ¥
    selected_model = st.selectbox(
        "OpenAI ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.",
        ["gpt-4o", "gpt-4o-mini", "gpt-3.5-turbo"],
        index=0,
    )  # OpenAI ëª¨ë¸ ì„ íƒ ì˜µì…˜
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (í”„ë¡¬í”„íŠ¸ ê¸°ë³¸ê°’)
    if "user_prefix_prompt" not in st.session_state:
        st.session_state["user_prefix_prompt"] = (
            "1. ë°ì´í„°ì˜ Null ê°’ì€ ì œì™¸í•˜ê³  ë‹µí•´ì£¼ê³ , ì œì™¸í–ˆì„ ê²½ìš°ì—ëŠ” ì œì™¸í•œ ê±´ìˆ˜ê°€ ì–¼ë§ˆë‚˜ ë˜ëŠ”ì§€ ê¼­ ë‚˜ì—ê²Œ ë§í•´ì£¼ì„¸ìš”.\
            2. ë¶„ì„ ê²°ê³¼ì— ëŒ€í•œ ì˜ˆì‹œë¥¼ ì°¸ê³ í•´ì„œ 3~4ê°œì˜ bullet pointë¡œ í•­ëª©í™”í•´ì„œ ë¶„ì„ì— ëŒ€í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.\
            - ì§ˆë¬¸: ìˆí¼ ì»¨í…ì¸ ëŠ” ë³´í†µ ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ì†Œë¹„ë˜ê³  ìˆë‚˜ìš”?\
            - ë¶„ì„ ê²°ê³¼ì— ëŒ€í•œ ì˜ˆì‹œ: \
            - ìˆí¼ ì´ìš©ìëŠ” ì£¼ë¡œ ì•Œê³ ë¦¬ì¦˜ì˜ ì¶”ì²œì„ ë”°ë¼ ì½˜í…ì¸ ë¥¼ ì†Œë¹„í•©ë‹ˆë‹¤.\
            - ì „ì²´ ìˆí¼ ì´ìš©ìì˜ 70% ì´ìƒì´ ì•Œê³ ë¦¬ì¦˜ì´ ì¶”ì²œí•´ì£¼ëŠ” ì˜ìƒì„ ì†Œë¹„í•©ë‹ˆë‹¤.\
            - ì•Œê³ ë¦¬ì¦˜ì— ëœ¨ëŠ” ì˜ìƒë§Œ ì†Œë¹„í•˜ëŠ” ë¹„ì¤‘ë„ 29.0%ì— ë‹¬í•©ë‹ˆë‹¤."
        )

    if "user_postfix_prompt" not in st.session_state:
        st.session_state["user_postfix_prompt"] = (
            "1.í†µì°°ì„ ë°˜ë“œì‹œ ìš”ì•½í•˜ê³ , ì£¼ìš” ìˆ˜ì¹˜ëŠ” ê·¸ë˜í”„ë¡œ ì‹œê°í™”í•´ì£¼ì„¸ìš”.\
            2.ë°ì´í„°ì— ëŒ€í•œ ì§‘ê³„ ê²°ê³¼ë¥¼ ì´ì•¼ê¸°í•  ë•ŒëŠ” ê°€ë…ì„±ì„ ìœ„í•´ì„œ í‘œ í˜•íƒœë¡œ í‘œì‹œí•´ì£¼ë©´ ì¢‹ê² ì–´ìš”.\
            3.ë¶„ì„í•  dimensionì´ 2ê°œ ì¼ë•ŒëŠ” cross-tabulation í˜•íƒœë¡œ ë³´ì—¬ì£¼ì„¸ìš”."
        )

    # ì‚¬ìš©ì ì…ë ¥ í•„ë“œ
    user_prefix_prompt = st.text_area(
        "ì‚¬ì „ í”„ë¡¬í”„íŠ¸ (prefix_prompt):",
        key="user_prefix_prompt",
    )

    user_postfix_prompt = st.text_area(
        "í›„ì† í”„ë¡¬í”„íŠ¸ (postfix_prompt):",
        key="user_postfix_prompt",
    )

    # ì»¬ëŸ¼ ê°€ì´ë“œë¼ì¸ ì…ë ¥
    user_column_guideline = st.text_area("ì»¬ëŸ¼ ê°€ì´ë“œë¼ì¸")

    apply_btn = st.button("ë°ì´í„° ë¶„ì„ ì‹œì‘")  # ë°ì´í„° ë¶„ì„ì„ ì‹œì‘í•˜ëŠ” ë²„íŠ¼
    # txt_prefix_prompt = st.empty()
    # txt_postfix_prompt = st.empty()
    txt_column_guideline = st.empty()


# ì½œë°± í•¨ìˆ˜
def tool_callback(tool) -> None:
    """
    ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì½œë°± í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Args:
        tool (dict): ì‹¤í–‰ëœ ë„êµ¬ ì •ë³´
    """
    if tool_name := tool.get("tool"):
        if tool_name == "python_repl_tool":
            tool_input = tool.get("tool_input", {})
            query = tool_input.get("code")
            if query:
                df_in_result = None
                with st.status("ë°ì´í„° ë¶„ì„ ì¤‘...", expanded=True) as status:
                    st.markdown(f"```python\n{query}\n```")
                    add_message(MessageRole.ASSISTANT, [MessageType.CODE, query])
                    if "df" in st.session_state:
                        result = st.session_state["python_tool"].invoke(
                            {"query": query}
                        )
                        if isinstance(result, pd.DataFrame):
                            df_in_result = result
                    status.update(label="ì½”ë“œ ì¶œë ¥", state="complete", expanded=False)

                if df_in_result is not None:
                    st.dataframe(df_in_result)
                    add_message(
                        MessageRole.ASSISTANT, [MessageType.DATAFRAME, df_in_result]
                    )

                if "plt.show" in query:
                    fig = plt.gcf()
                    st.pyplot(fig)
                    add_message(MessageRole.ASSISTANT, [MessageType.FIGURE, fig])

                return result
            else:
                st.error(
                    "ë°ì´í„°í”„ë ˆì„ì´ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. CSV íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
                )
                return


def observation_callback(observation) -> None:
    """
    ê´€ì°° ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì½œë°± í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Args:
        observation (dict): ê´€ì°° ê²°ê³¼
    """
    if "observation" in observation:
        obs = observation["observation"]
        if isinstance(obs, str) and "Error" in obs:
            st.error(obs)
            st.session_state["messages"][-1][
                1
            ].clear()  # ì—ëŸ¬ ë°œìƒ ì‹œ ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì‚­ì œ


# ì—ì´ì „íŠ¸ ìƒì„± í•¨ìˆ˜
def create_agent(
    dataframe,
    selected_model="gpt-4o",
    user_prefix_prompt=None,
    user_postfix_prompt=None,
    user_column_guideline=None,
):
    """
    ë°ì´í„°í”„ë ˆì„ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Args:
        dataframe (pd.DataFrame): ë¶„ì„í•  ë°ì´í„°í”„ë ˆì„
        selected_model (str, optional): ì‚¬ìš©í•  OpenAI ëª¨ë¸. ê¸°ë³¸ê°’ì€ "gpt-4o"

    Returns:
        Agent: ìƒì„±ëœ ë°ì´í„°í”„ë ˆì„ ì—ì´ì „íŠ¸
    """
    from dataanalysis import DataAnalysisAgent

    return DataAnalysisAgent(
        dataframe,
        model_name=selected_model,
        prefix_prompt=user_prefix_prompt,
        postfix_prompt=user_postfix_prompt,
        column_guideline=user_column_guideline,
    )


# ì§ˆë¬¸ ì²˜ë¦¬ í•¨ìˆ˜
def ask(query):
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ê³  ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Args:
        query (str): ì‚¬ìš©ìì˜ ì§ˆë¬¸
    """
    if "agent" in st.session_state:
        st.chat_message("user").write(query)
        add_message(MessageRole.USER, [MessageType.TEXT, query])

        agent = st.session_state["agent"]
        response = agent.stream(query, "abc123")

        ai_answer = ""
        parser_callback = AgentCallbacks(tool_callback, observation_callback)
        stream_parser = AgentStreamParser(parser_callback)

        with st.chat_message("assistant"):
            for step in response:
                stream_parser.process_agent_steps(step)
                if "output" in step:
                    ai_answer += step["output"]
            st.write(ai_answer)

        add_message(MessageRole.ASSISTANT, [MessageType.TEXT, ai_answer])


# ë©”ì¸ ë¡œì§
if clear_btn:
    st.session_state["messages"] = []  # ëŒ€í™” ë‚´ìš© ì´ˆê¸°í™”

if apply_btn and uploaded_file:
    loaded_data = pd.read_csv(uploaded_file)  # CSV íŒŒì¼ ë¡œë“œ
    st.session_state["df"] = loaded_data  # ë°ì´í„°í”„ë ˆì„ ì €ì¥
    st.session_state["python_tool"] = PythonAstREPLTool()  # Python ì‹¤í–‰ ë„êµ¬ ìƒì„±
    st.session_state["python_tool"].locals[
        "df"
    ] = loaded_data  # ë°ì´í„°í”„ë ˆì„ì„ Python ì‹¤í–‰ í™˜ê²½ì— ì¶”ê°€

    st.session_state["agent"] = create_agent(
        loaded_data,
        selected_model,
        user_prefix_prompt=user_prefix_prompt.replace("{", "{{").replace("}", "}}"),
        user_postfix_prompt=user_postfix_prompt.replace("{", "{{").replace("}", "}}"),
        user_column_guideline=(
            user_column_guideline.replace("{", "{{").replace("}", "}}")
            if user_column_guideline
            else None
        ),
    )  # ì—ì´ì „íŠ¸ ìƒì„±

    st.success("ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ëŒ€í™”ë¥¼ ì‹œì‘í•´ ì£¼ì„¸ìš”!")
elif apply_btn:
    st.warning("íŒŒì¼ì„ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”.")


if "agent" in st.session_state:
    updated_column_guideline = txt_column_guideline.markdown(
        f"**ì»¬ëŸ¼ ê°€ì´ë“œë¼ì¸**\n\n```\n{st.session_state['agent'].column_guideline}\n```"
    )

print_messages()  # ì €ì¥ëœ ë©”ì‹œì§€ ì¶œë ¥

user_input = st.chat_input("ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì„¸ìš”!")  # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if user_input:
    ask(user_input)  # ì‚¬ìš©ì ì§ˆë¬¸ ì²˜ë¦¬
